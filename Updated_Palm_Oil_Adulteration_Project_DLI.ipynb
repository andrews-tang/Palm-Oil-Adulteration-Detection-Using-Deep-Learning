{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV5Vr9yJHu9D"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/intro/Intro_to_Weights_&_Biases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "<!--- @wandbcode{intro-colab} -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trLfwcq0Hu9H"
      },
      "source": [
        "<img src=\"http://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
        "<!--- @wandbcode{intro-colab} -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0ehi0ilSZdU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc84aa2c-47b3-44c1-b21c-f9bfb1305e28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.6/188.6 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.8/218.8 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install Pillow\n",
        "!pip install  wandb -qU"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **All Imports Here**"
      ],
      "metadata": {
        "id": "CMtaWR-UzzH-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Avu1QZ6hTF5w"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "from torchvision.transforms import transforms\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Drive for Dataset Retrieval"
      ],
      "metadata": {
        "id": "HKvoek9az-hQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "cocastic_drive_account = \"drive/MyDrive/Palm_oil_Adulteration_Dataset/Palm_Oil_Dataset_Demo\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNFJAek7alZ8",
        "outputId": "d6d4021b-6b19-46fd-dc16-1adffeed1f56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Log in to your W&B account**"
      ],
      "metadata": {
        "id": "XtvpOgQp0K7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "key=r\"806d3d4c69ab21ca32efab6cdb0f286a7410f3db\""
      ],
      "metadata": {
        "id": "Fgoe-aBIbGLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dp4LP4vHu9L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "bc0ab3d9-e5b4-4d58-b250-c3fdea32f578"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **All Custom Classes**"
      ],
      "metadata": {
        "id": "U-DKUheB0QX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomPalmOilDataset(Dataset):\n",
        "    def __init__(self, root_dir = cocastic_drive_account, transform = None, target_transform = None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Assuming 'Pure' corresponds to label 0 and 'Adulterated' corresponds to label 1\n",
        "        label_mapping = {'Pure': 0, 'Adulterated': 1}\n",
        "\n",
        "        for label_folder in os.listdir(root_dir):\n",
        "            label = label_mapping.get(label_folder, -1)  # Assign -1 if folder not in mapping\n",
        "            if label != -1:\n",
        "                label_folder_path = os.path.join(root_dir, label_folder)\n",
        "                for image_name in os.listdir(label_folder_path):\n",
        "                    image_path = os.path.join(label_folder_path, image_name)\n",
        "                    self.image_paths.append(image_path)\n",
        "                    self.labels.append(label)\n",
        "\n",
        "\n",
        "        combined_data = list(zip(self.image_paths, self.labels))\n",
        "        random.shuffle(combined_data)\n",
        "        self.image_paths, self.labels = zip(*combined_data)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class PalmOilClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PalmOilClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.conv3 = nn.Conv2d(16, 32, 5)  # Adding the third convolutional layer\n",
        "        self.fc1 = nn.Linear(32 * 24 * 24, 120)  # Adjusting the input size for the fully connected layers\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 2)  # Output has 2 units for binary classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))  # Applying the third convolutional layer\n",
        "        x = torch.flatten(x, 1)  # Flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)  # Output layer with 2 units for binary classification\n",
        "        return x"
      ],
      "metadata": {
        "id": "Pv-FgnIVzb2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## All Custom Functions"
      ],
      "metadata": {
        "id": "VZ15cPd-0dR_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7_-Az66lJF2"
      },
      "outputs": [],
      "source": [
        "\n",
        "def custom_collate_fn(batch):\n",
        "    images = [item[0] for item in batch]\n",
        "    labels = [item[1] for item in batch]\n",
        "    images = torch.stack(images, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def validate_model(model, valid_dl, loss_func, log_images=False, batch_idx=0):\n",
        "    \"Compute performance of the model on the validation dataset and log a wandb.Table\"\n",
        "    model.eval()\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    val_loss = 0.\n",
        "    with torch.inference_mode():\n",
        "        correct = 0\n",
        "        for i, (images, labels) in enumerate(valid_dl):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass ➡\n",
        "            outputs = model(images)\n",
        "            val_loss += loss_func(outputs, labels)*labels.size(0)\n",
        "\n",
        "            # Compute accuracy and accumulate\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Log one batch of images to the dashboard, always same batch_idx.\n",
        "            if i==batch_idx and log_images:\n",
        "                log_image_table(images, predicted, labels, outputs.softmax(dim=1))\n",
        "    return val_loss / len(valid_dl.dataset), correct / len(valid_dl.dataset)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def log_image_table(images, predicted, labels, probs):\n",
        "    \"Log a wandb.Table with (img, pred, target, scores)\"\n",
        "    # 🐝 Create a wandb Table to log images, labels, and predictions\n",
        "    table = wandb.Table(columns=[\"image\", \"pred\", \"target\"] + [f\"score_{i}\" for i in range(2)])\n",
        "    for img, pred, targ, prob in zip(images.to(\"cpu\"), predicted.to(\"cpu\"), labels.to(\"cpu\"), probs.to(\"cpu\")):\n",
        "        # Assuming your input images are in RGB format\n",
        "        data = [wandb.Image(img.numpy().transpose(1, 2, 0) * 255), pred, targ] + prob.numpy().tolist()\n",
        "        table.add_data(*data)\n",
        "    wandb.log({\"predictions_table\": table}, commit=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_model(num_of_runs=2):\n",
        "  for _ in range(num_of_runs):\n",
        "    wandb.init(project = \"Updated_Palm_Oil_Adulteration_Project_DLI\",\n",
        "               config = {\n",
        "                \"epochs\": 8,\n",
        "                \"batch_size\": 64,\n",
        "                \"lr\": 0.0018})\n",
        "\n",
        "    # Copy your config\n",
        "    config = wandb.config\n",
        "    # Set device (CPU or GPU)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
        "    val_dataloader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
        "    n_steps_per_epoch = math.ceil(len(train_dataloader.dataset) / config.batch_size)\n",
        "\n",
        "    model = PalmOilClassifier()\n",
        "    model.to(device)\n",
        "\n",
        "\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
        "\n",
        "\n",
        "    # Move the model to the appropriate device\n",
        "    model.to(device)\n",
        "\n",
        "    # Training loop\n",
        "\n",
        "    example_ct = 0\n",
        "    step_ct = 0\n",
        "    for epoch in range(config.epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        for step, (images, labels) in enumerate(train_dataloader):\n",
        "            # Move data to the appropriate device\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            train_loss = loss_func(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            example_ct += len(images)\n",
        "            metrics = {\"train/train_loss\": train_loss,\n",
        "                       \"train/epoch\": (step + 1 + (n_steps_per_epoch * epoch)) / n_steps_per_epoch,\n",
        "                       \"train/example_ct\": example_ct}\n",
        "\n",
        "            if step + 1 < n_steps_per_epoch:\n",
        "                # 🐝 Log train metrics to wandb\n",
        "                wandb.log(metrics)\n",
        "\n",
        "            step_ct += 1\n",
        "\n",
        "\n",
        "            val_loss, accuracy = validate_model(model, val_dataloader, loss_func, log_images=(epoch==(config.epochs-1)))\n",
        "\n",
        "\n",
        "            # Log train and validation metrics to wandb\n",
        "            val_metrics = {\"val/val_loss\": val_loss,\n",
        "                       \"val/val_accuracy\": accuracy}\n",
        "            wandb.log({**metrics, **val_metrics})\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            print(f\"Train Loss: {train_loss:.3f}, Valid Loss: {val_loss:3f}, Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "    # If you had a test set, this is how you could log it as a Summary metric\n",
        "    wandb.summary['test_accuracy'] = 0.8\n",
        "\n",
        "    # 🐝 Close your wandb run\n",
        "    wandb.finish()\n",
        "    torch.save(model, cocastic_drive_account+'/model.pth')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "test_size = 0.2  # You can adjust the test size as needed\n",
        "random_seed = 42  # Set a seed for reproducibility\n",
        "batch_size = 64\n",
        "\n",
        "dataset = CustomPalmOilDataset(transform=transform)\n",
        "\n",
        "# Define the percentage split for training and testing\n",
        "train_percentage = 0.8  # 80% for training, 20% for testing\n",
        "dataset_size = len(dataset)\n",
        "train_size = int(train_percentage * dataset_size)\n",
        "test_size = dataset_size - train_size\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "print(f\"Dataset Size: {dataset_size}, Train Size: {train_size}, Test Size: {test_size}\")"
      ],
      "metadata": {
        "id": "n9Ns-GCQ5Wvx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f75b4ebb-3379-4d6d-df26-504ecb28b80e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Size: 1000, Train Size: 800, Test Size: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1316584ebe144e61b89a9d0bb94422e2",
            "b5b245fff5fd48eb87dcde9fd7357247",
            "0b564972fd49480f94fbec4eb999be62",
            "3a37d7fc32774a749c2ee4d2c1272561",
            "c5d28a644a834a0c878ba03362f667c7",
            "a0415b0c5b864c7c873771f54c2e42db",
            "c92e15f7a0624339836c624ba9b40b8a",
            "51d981534b334f28a3661eaa7faa47d3"
          ]
        },
        "id": "zXcVS-UD0SER",
        "outputId": "f810c47d-275f-440e-e82d-3ba96cef9394"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myelsongdabuo-tang\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230904_235250-t2yjo6if</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yelsongdabuo-tang/Updated_Palm_Oil_Adulteration_Project_DLI/runs/t2yjo6if' target=\"_blank\">amber-grass-96</a></strong> to <a href='https://wandb.ai/yelsongdabuo-tang/Updated_Palm_Oil_Adulteration_Project_DLI' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/yelsongdabuo-tang/Updated_Palm_Oil_Adulteration_Project_DLI' target=\"_blank\">https://wandb.ai/yelsongdabuo-tang/Updated_Palm_Oil_Adulteration_Project_DLI</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/yelsongdabuo-tang/Updated_Palm_Oil_Adulteration_Project_DLI/runs/t2yjo6if' target=\"_blank\">https://wandb.ai/yelsongdabuo-tang/Updated_Palm_Oil_Adulteration_Project_DLI/runs/t2yjo6if</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.693, Valid Loss: 0.688770, Accuracy: 0.52\n",
            "Train Loss: 0.700, Valid Loss: 0.703599, Accuracy: 0.48\n",
            "Train Loss: 0.679, Valid Loss: 0.685772, Accuracy: 0.48\n",
            "Train Loss: 0.657, Valid Loss: 0.637375, Accuracy: 0.65\n",
            "Train Loss: 0.654, Valid Loss: 0.626609, Accuracy: 0.61\n",
            "Train Loss: 0.550, Valid Loss: 0.670080, Accuracy: 0.60\n",
            "Train Loss: 0.638, Valid Loss: 0.585839, Accuracy: 0.66\n",
            "Train Loss: 0.480, Valid Loss: 0.675913, Accuracy: 0.62\n",
            "Train Loss: 0.601, Valid Loss: 0.554813, Accuracy: 0.74\n",
            "Train Loss: 0.543, Valid Loss: 0.557004, Accuracy: 0.76\n",
            "Train Loss: 0.531, Valid Loss: 0.522778, Accuracy: 0.77\n",
            "Train Loss: 0.649, Valid Loss: 0.543724, Accuracy: 0.75\n",
            "Train Loss: 0.433, Valid Loss: 0.562462, Accuracy: 0.70\n",
            "Train Loss: 0.540, Valid Loss: 0.554233, Accuracy: 0.72\n",
            "Train Loss: 0.556, Valid Loss: 0.535004, Accuracy: 0.77\n",
            "Train Loss: 0.537, Valid Loss: 0.513751, Accuracy: 0.80\n",
            "Train Loss: 0.517, Valid Loss: 0.487147, Accuracy: 0.81\n",
            "Train Loss: 0.425, Valid Loss: 0.460365, Accuracy: 0.81\n",
            "Train Loss: 0.345, Valid Loss: 0.489306, Accuracy: 0.79\n",
            "Train Loss: 0.405, Valid Loss: 0.441620, Accuracy: 0.80\n",
            "Train Loss: 0.348, Valid Loss: 0.434450, Accuracy: 0.81\n",
            "Train Loss: 0.355, Valid Loss: 0.440746, Accuracy: 0.82\n",
            "Train Loss: 0.170, Valid Loss: 0.472270, Accuracy: 0.82\n",
            "Train Loss: 0.117, Valid Loss: 0.532149, Accuracy: 0.79\n",
            "Train Loss: 0.893, Valid Loss: 0.603338, Accuracy: 0.74\n",
            "Train Loss: 0.405, Valid Loss: 0.485544, Accuracy: 0.76\n",
            "Train Loss: 0.346, Valid Loss: 0.440993, Accuracy: 0.77\n",
            "Train Loss: 0.424, Valid Loss: 0.399972, Accuracy: 0.83\n",
            "Train Loss: 0.310, Valid Loss: 0.380595, Accuracy: 0.82\n",
            "Train Loss: 0.308, Valid Loss: 0.384805, Accuracy: 0.82\n",
            "Train Loss: 0.334, Valid Loss: 0.364686, Accuracy: 0.83\n",
            "Train Loss: 0.357, Valid Loss: 0.350636, Accuracy: 0.85\n",
            "Train Loss: 0.282, Valid Loss: 0.351193, Accuracy: 0.89\n",
            "Train Loss: 0.283, Valid Loss: 0.329312, Accuracy: 0.86\n",
            "Train Loss: 0.321, Valid Loss: 0.323229, Accuracy: 0.84\n",
            "Train Loss: 0.231, Valid Loss: 0.340081, Accuracy: 0.84\n",
            "Train Loss: 0.234, Valid Loss: 0.355818, Accuracy: 0.83\n",
            "Train Loss: 0.270, Valid Loss: 0.346993, Accuracy: 0.83\n",
            "Train Loss: 0.261, Valid Loss: 0.352991, Accuracy: 0.84\n",
            "Train Loss: 0.187, Valid Loss: 0.381819, Accuracy: 0.82\n",
            "Train Loss: 0.321, Valid Loss: 0.336061, Accuracy: 0.89\n",
            "Train Loss: 0.285, Valid Loss: 0.323109, Accuracy: 0.87\n",
            "Train Loss: 0.254, Valid Loss: 0.394147, Accuracy: 0.83\n",
            "Train Loss: 0.182, Valid Loss: 0.336175, Accuracy: 0.84\n",
            "Train Loss: 0.182, Valid Loss: 0.310861, Accuracy: 0.88\n",
            "Train Loss: 0.257, Valid Loss: 0.355086, Accuracy: 0.86\n",
            "Train Loss: 0.349, Valid Loss: 0.290148, Accuracy: 0.88\n",
            "Train Loss: 0.236, Valid Loss: 0.304153, Accuracy: 0.86\n",
            "Train Loss: 0.311, Valid Loss: 0.297262, Accuracy: 0.87\n",
            "Train Loss: 0.177, Valid Loss: 0.298844, Accuracy: 0.89\n",
            "Train Loss: 0.236, Valid Loss: 0.284213, Accuracy: 0.89\n",
            "Train Loss: 0.299, Valid Loss: 0.296212, Accuracy: 0.89\n",
            "Train Loss: 0.200, Valid Loss: 0.293638, Accuracy: 0.88\n",
            "Train Loss: 0.188, Valid Loss: 0.259637, Accuracy: 0.90\n",
            "Train Loss: 0.205, Valid Loss: 0.280272, Accuracy: 0.88\n",
            "Train Loss: 0.173, Valid Loss: 0.332796, Accuracy: 0.84\n",
            "Train Loss: 0.199, Valid Loss: 0.302524, Accuracy: 0.85\n",
            "Train Loss: 0.256, Valid Loss: 0.297768, Accuracy: 0.86\n",
            "Train Loss: 0.238, Valid Loss: 0.230543, Accuracy: 0.90\n",
            "Train Loss: 0.177, Valid Loss: 0.223898, Accuracy: 0.89\n",
            "Train Loss: 0.175, Valid Loss: 0.235047, Accuracy: 0.90\n",
            "Train Loss: 0.111, Valid Loss: 0.243344, Accuracy: 0.89\n",
            "Train Loss: 0.157, Valid Loss: 0.292993, Accuracy: 0.91\n",
            "Train Loss: 0.352, Valid Loss: 0.228138, Accuracy: 0.91\n",
            "Train Loss: 0.090, Valid Loss: 0.193618, Accuracy: 0.91\n",
            "Train Loss: 0.319, Valid Loss: 0.182830, Accuracy: 0.92\n",
            "Train Loss: 0.099, Valid Loss: 0.219837, Accuracy: 0.91\n",
            "Train Loss: 0.107, Valid Loss: 0.225448, Accuracy: 0.90\n",
            "Train Loss: 0.139, Valid Loss: 0.211641, Accuracy: 0.92\n",
            "Train Loss: 0.236, Valid Loss: 0.219988, Accuracy: 0.92\n",
            "Train Loss: 0.083, Valid Loss: 0.216804, Accuracy: 0.91\n",
            "Train Loss: 0.146, Valid Loss: 0.230064, Accuracy: 0.90\n",
            "Train Loss: 0.119, Valid Loss: 0.204306, Accuracy: 0.92\n",
            "Train Loss: 0.040, Valid Loss: 0.192024, Accuracy: 0.90\n",
            "Train Loss: 0.182, Valid Loss: 0.226520, Accuracy: 0.93\n",
            "Train Loss: 0.110, Valid Loss: 0.200732, Accuracy: 0.92\n",
            "Train Loss: 0.300, Valid Loss: 0.195663, Accuracy: 0.91\n",
            "Train Loss: 0.051, Valid Loss: 0.417911, Accuracy: 0.84\n",
            "Train Loss: 0.288, Valid Loss: 0.226538, Accuracy: 0.92\n",
            "Train Loss: 0.167, Valid Loss: 0.253005, Accuracy: 0.89\n",
            "Train Loss: 0.132, Valid Loss: 0.290698, Accuracy: 0.89\n",
            "Train Loss: 0.130, Valid Loss: 0.287076, Accuracy: 0.89\n",
            "Train Loss: 0.310, Valid Loss: 0.182111, Accuracy: 0.94\n",
            "Train Loss: 0.118, Valid Loss: 0.206981, Accuracy: 0.90\n",
            "Train Loss: 0.117, Valid Loss: 0.325182, Accuracy: 0.86\n",
            "Train Loss: 0.337, Valid Loss: 0.305946, Accuracy: 0.86\n",
            "Train Loss: 0.185, Valid Loss: 0.225437, Accuracy: 0.90\n",
            "Train Loss: 0.194, Valid Loss: 0.273792, Accuracy: 0.89\n",
            "Train Loss: 0.156, Valid Loss: 0.327733, Accuracy: 0.86\n",
            "Train Loss: 0.295, Valid Loss: 0.297319, Accuracy: 0.87\n",
            "Train Loss: 0.300, Valid Loss: 0.256224, Accuracy: 0.91\n",
            "Train Loss: 0.141, Valid Loss: 0.233867, Accuracy: 0.92\n",
            "Train Loss: 0.218, Valid Loss: 0.212631, Accuracy: 0.92\n",
            "Train Loss: 0.136, Valid Loss: 0.219005, Accuracy: 0.90\n",
            "Train Loss: 0.174, Valid Loss: 0.222181, Accuracy: 0.91\n",
            "Train Loss: 0.089, Valid Loss: 0.221930, Accuracy: 0.92\n",
            "Train Loss: 0.122, Valid Loss: 0.219020, Accuracy: 0.91\n",
            "Train Loss: 0.244, Valid Loss: 0.189750, Accuracy: 0.93\n",
            "Train Loss: 0.103, Valid Loss: 0.161793, Accuracy: 0.95\n",
            "Train Loss: 0.136, Valid Loss: 0.148428, Accuracy: 0.96\n",
            "Train Loss: 0.053, Valid Loss: 0.145101, Accuracy: 0.94\n",
            "Train Loss: 0.104, Valid Loss: 0.144715, Accuracy: 0.95\n",
            "Train Loss: 0.044, Valid Loss: 0.158624, Accuracy: 0.94\n",
            "Train Loss: 0.158, Valid Loss: 0.166583, Accuracy: 0.94\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/example_ct</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/train_loss</td><td>██▆▆▆▆▆▄▄▂▄▄▄▄▃▄▃▃▃▃▃▂▃▂▂▂▃▂▂▄▂▂▂▂▄▃▁▃▁▂</td></tr><tr><td>val/val_accuracy</td><td>▂▁▃▃▅▅▆▆▆▆▅▆▇▆▆▆▆▇▇▇▇▆▇▇▇▇█▇▇▇▇▇▇▇▇█████</td></tr><tr><td>val/val_loss</td><td>████▆▆▆▅▅▆▅▄▄▃▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▃▃▃▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.8</td></tr><tr><td>train/epoch</td><td>8.0</td></tr><tr><td>train/example_ct</td><td>6400</td></tr><tr><td>train/train_loss</td><td>0.15766</td></tr><tr><td>val/val_accuracy</td><td>0.945</td></tr><tr><td>val/val_loss</td><td>0.16658</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">amber-grass-96</strong> at: <a href='https://wandb.ai/yelsongdabuo-tang/Updated_Palm_Oil_Adulteration_Project_DLI/runs/t2yjo6if' target=\"_blank\">https://wandb.ai/yelsongdabuo-tang/Updated_Palm_Oil_Adulteration_Project_DLI/runs/t2yjo6if</a><br/>Synced 5 W&B file(s), 13 media file(s), 845 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230904_235250-t2yjo6if/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230905_011709-gj6k78no</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yelsongdabuo-tang/Updated_Palm_Oil_Adulteration_Project_DLI/runs/gj6k78no' target=\"_blank\">snowy-disco-97</a></strong> to <a href='https://wandb.ai/yelsongdabuo-tang/Updated_Palm_Oil_Adulteration_Project_DLI' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/yelsongdabuo-tang/Updated_Palm_Oil_Adulteration_Project_DLI' target=\"_blank\">https://wandb.ai/yelsongdabuo-tang/Updated_Palm_Oil_Adulteration_Project_DLI</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/yelsongdabuo-tang/Updated_Palm_Oil_Adulteration_Project_DLI/runs/gj6k78no' target=\"_blank\">https://wandb.ai/yelsongdabuo-tang/Updated_Palm_Oil_Adulteration_Project_DLI/runs/gj6k78no</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.694, Valid Loss: 0.689404, Accuracy: 0.48\n",
            "Train Loss: 0.682, Valid Loss: 0.976093, Accuracy: 0.48\n",
            "Train Loss: 0.957, Valid Loss: 0.665639, Accuracy: 0.63\n",
            "Train Loss: 0.678, Valid Loss: 0.683920, Accuracy: 0.52\n",
            "Train Loss: 0.745, Valid Loss: 0.684597, Accuracy: 0.52\n",
            "Train Loss: 0.690, Valid Loss: 0.687124, Accuracy: 0.57\n",
            "Train Loss: 0.689, Valid Loss: 0.687195, Accuracy: 0.75\n",
            "Train Loss: 0.686, Valid Loss: 0.684800, Accuracy: 0.53\n",
            "Train Loss: 0.684, Valid Loss: 0.682704, Accuracy: 0.48\n",
            "Train Loss: 0.677, Valid Loss: 0.683834, Accuracy: 0.48\n",
            "Train Loss: 0.672, Valid Loss: 0.681394, Accuracy: 0.48\n",
            "Train Loss: 0.674, Valid Loss: 0.669697, Accuracy: 0.48\n",
            "Train Loss: 0.660, Valid Loss: 0.650719, Accuracy: 0.61\n",
            "Train Loss: 0.631, Valid Loss: 0.631440, Accuracy: 0.69\n",
            "Train Loss: 0.618, Valid Loss: 0.610008, Accuracy: 0.74\n",
            "Train Loss: 0.648, Valid Loss: 0.593985, Accuracy: 0.69\n",
            "Train Loss: 0.568, Valid Loss: 0.567108, Accuracy: 0.74\n",
            "Train Loss: 0.542, Valid Loss: 0.630780, Accuracy: 0.65\n",
            "Train Loss: 0.618, Valid Loss: 0.575980, Accuracy: 0.69\n",
            "Train Loss: 0.583, Valid Loss: 0.521145, Accuracy: 0.74\n",
            "Train Loss: 0.483, Valid Loss: 0.550386, Accuracy: 0.76\n",
            "Train Loss: 0.402, Valid Loss: 0.502371, Accuracy: 0.79\n",
            "Train Loss: 0.454, Valid Loss: 0.563886, Accuracy: 0.77\n",
            "Train Loss: 0.398, Valid Loss: 0.719633, Accuracy: 0.66\n",
            "Train Loss: 0.539, Valid Loss: 0.577555, Accuracy: 0.71\n",
            "Train Loss: 0.353, Valid Loss: 0.516827, Accuracy: 0.72\n",
            "Train Loss: 0.430, Valid Loss: 0.494985, Accuracy: 0.74\n",
            "Train Loss: 0.478, Valid Loss: 0.467749, Accuracy: 0.78\n",
            "Train Loss: 0.441, Valid Loss: 0.452583, Accuracy: 0.78\n",
            "Train Loss: 0.376, Valid Loss: 0.447765, Accuracy: 0.79\n",
            "Train Loss: 0.380, Valid Loss: 0.445843, Accuracy: 0.79\n",
            "Train Loss: 0.333, Valid Loss: 0.463374, Accuracy: 0.77\n",
            "Train Loss: 0.339, Valid Loss: 0.440276, Accuracy: 0.78\n",
            "Train Loss: 0.323, Valid Loss: 0.427236, Accuracy: 0.77\n",
            "Train Loss: 0.271, Valid Loss: 0.423932, Accuracy: 0.79\n",
            "Train Loss: 0.397, Valid Loss: 0.451822, Accuracy: 0.81\n",
            "Train Loss: 0.328, Valid Loss: 0.426399, Accuracy: 0.79\n",
            "Train Loss: 0.314, Valid Loss: 0.421053, Accuracy: 0.80\n",
            "Train Loss: 0.381, Valid Loss: 0.394807, Accuracy: 0.81\n",
            "Train Loss: 0.292, Valid Loss: 0.352594, Accuracy: 0.81\n",
            "Train Loss: 0.381, Valid Loss: 0.347529, Accuracy: 0.82\n",
            "Train Loss: 0.234, Valid Loss: 0.351342, Accuracy: 0.82\n",
            "Train Loss: 0.274, Valid Loss: 0.344966, Accuracy: 0.84\n",
            "Train Loss: 0.286, Valid Loss: 0.331599, Accuracy: 0.85\n",
            "Train Loss: 0.251, Valid Loss: 0.313578, Accuracy: 0.85\n",
            "Train Loss: 0.185, Valid Loss: 0.324767, Accuracy: 0.84\n",
            "Train Loss: 0.172, Valid Loss: 0.348325, Accuracy: 0.84\n",
            "Train Loss: 0.360, Valid Loss: 0.327248, Accuracy: 0.85\n",
            "Train Loss: 0.176, Valid Loss: 0.274286, Accuracy: 0.89\n",
            "Train Loss: 0.304, Valid Loss: 0.312087, Accuracy: 0.86\n",
            "Train Loss: 0.217, Valid Loss: 0.283522, Accuracy: 0.88\n",
            "Train Loss: 0.366, Valid Loss: 0.334324, Accuracy: 0.87\n",
            "Train Loss: 0.207, Valid Loss: 0.410129, Accuracy: 0.82\n",
            "Train Loss: 0.232, Valid Loss: 0.351661, Accuracy: 0.85\n",
            "Train Loss: 0.390, Valid Loss: 0.253999, Accuracy: 0.88\n",
            "Train Loss: 0.212, Valid Loss: 0.240871, Accuracy: 0.89\n",
            "Train Loss: 0.246, Valid Loss: 0.302698, Accuracy: 0.84\n",
            "Train Loss: 0.149, Valid Loss: 0.323048, Accuracy: 0.84\n",
            "Train Loss: 0.314, Valid Loss: 0.246684, Accuracy: 0.89\n",
            "Train Loss: 0.304, Valid Loss: 0.297778, Accuracy: 0.89\n",
            "Train Loss: 0.244, Valid Loss: 0.249981, Accuracy: 0.91\n",
            "Train Loss: 0.214, Valid Loss: 0.236682, Accuracy: 0.90\n",
            "Train Loss: 0.134, Valid Loss: 0.292377, Accuracy: 0.88\n",
            "Train Loss: 0.165, Valid Loss: 0.329019, Accuracy: 0.84\n",
            "Train Loss: 0.555, Valid Loss: 0.291350, Accuracy: 0.90\n",
            "Train Loss: 0.167, Valid Loss: 0.382494, Accuracy: 0.87\n",
            "Train Loss: 0.353, Valid Loss: 0.351510, Accuracy: 0.88\n",
            "Train Loss: 0.258, Valid Loss: 0.392201, Accuracy: 0.83\n",
            "Train Loss: 0.330, Valid Loss: 0.346416, Accuracy: 0.86\n",
            "Train Loss: 0.278, Valid Loss: 0.285625, Accuracy: 0.91\n",
            "Train Loss: 0.149, Valid Loss: 0.281607, Accuracy: 0.90\n",
            "Train Loss: 0.226, Valid Loss: 0.268885, Accuracy: 0.91\n",
            "Train Loss: 0.248, Valid Loss: 0.251541, Accuracy: 0.88\n",
            "Train Loss: 0.132, Valid Loss: 0.321328, Accuracy: 0.85\n",
            "Train Loss: 0.409, Valid Loss: 0.299108, Accuracy: 0.85\n",
            "Train Loss: 0.197, Valid Loss: 0.239900, Accuracy: 0.88\n",
            "Train Loss: 0.081, Valid Loss: 0.277050, Accuracy: 0.88\n",
            "Train Loss: 0.209, Valid Loss: 0.274379, Accuracy: 0.88\n",
            "Train Loss: 0.114, Valid Loss: 0.262619, Accuracy: 0.88\n",
            "Train Loss: 0.185, Valid Loss: 0.230364, Accuracy: 0.90\n",
            "Train Loss: 0.115, Valid Loss: 0.232226, Accuracy: 0.91\n",
            "Train Loss: 0.275, Valid Loss: 0.246500, Accuracy: 0.89\n",
            "Train Loss: 0.177, Valid Loss: 0.245520, Accuracy: 0.88\n",
            "Train Loss: 0.128, Valid Loss: 0.224504, Accuracy: 0.89\n",
            "Train Loss: 0.104, Valid Loss: 0.196561, Accuracy: 0.91\n",
            "Train Loss: 0.114, Valid Loss: 0.183998, Accuracy: 0.92\n",
            "Train Loss: 0.122, Valid Loss: 0.187768, Accuracy: 0.91\n",
            "Train Loss: 0.118, Valid Loss: 0.199510, Accuracy: 0.89\n",
            "Train Loss: 0.094, Valid Loss: 0.200578, Accuracy: 0.89\n",
            "Train Loss: 0.103, Valid Loss: 0.204280, Accuracy: 0.90\n",
            "Train Loss: 0.078, Valid Loss: 0.207414, Accuracy: 0.90\n",
            "Train Loss: 0.094, Valid Loss: 0.197368, Accuracy: 0.92\n",
            "Train Loss: 0.111, Valid Loss: 0.189448, Accuracy: 0.94\n",
            "Train Loss: 0.036, Valid Loss: 0.201247, Accuracy: 0.94\n",
            "Train Loss: 0.151, Valid Loss: 0.189766, Accuracy: 0.93\n",
            "Train Loss: 0.178, Valid Loss: 0.183652, Accuracy: 0.93\n",
            "Train Loss: 0.061, Valid Loss: 0.141673, Accuracy: 0.94\n",
            "Train Loss: 0.077, Valid Loss: 0.116238, Accuracy: 0.95\n",
            "Train Loss: 0.101, Valid Loss: 0.117105, Accuracy: 0.95\n",
            "Train Loss: 0.046, Valid Loss: 0.124718, Accuracy: 0.95\n",
            "Train Loss: 0.120, Valid Loss: 0.124667, Accuracy: 0.95\n",
            "Train Loss: 0.254, Valid Loss: 0.134872, Accuracy: 0.94\n",
            "Train Loss: 0.096, Valid Loss: 0.151410, Accuracy: 0.91\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='46.194 MB of 46.194 MB uploaded (42.402 MB deduped)\\r'), FloatProgress(value=1.0, …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1316584ebe144e61b89a9d0bb94422e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/example_ct</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/train_loss</td><td>▆█▆▆▆▅▅▅▄▄▄▄▃▃▃▄▃▂▃▂▂▂▂▃▂▃▃▂▄▂▂▂▂▂▁▁▂▁▁▁</td></tr><tr><td>val/val_accuracy</td><td>▁▃▂▂▁▄▄▄▅▄▅▅▅▆▆▆▆▇▇▇▆▇▇▇▆▇▇▇▆▇▇▇▇▇▇▇███▇</td></tr><tr><td>val/val_loss</td><td>█▇███▇▇▆▅█▅▅▅▅▅▄▄▃▃▃▄▂▂▂▃▄▄▃▃▂▃▂▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.8</td></tr><tr><td>train/epoch</td><td>8.0</td></tr><tr><td>train/example_ct</td><td>6400</td></tr><tr><td>train/train_loss</td><td>0.09602</td></tr><tr><td>val/val_accuracy</td><td>0.905</td></tr><tr><td>val/val_loss</td><td>0.15141</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">snowy-disco-97</strong> at: <a href='https://wandb.ai/yelsongdabuo-tang/Updated_Palm_Oil_Adulteration_Project_DLI/runs/gj6k78no' target=\"_blank\">https://wandb.ai/yelsongdabuo-tang/Updated_Palm_Oil_Adulteration_Project_DLI/runs/gj6k78no</a><br/>Synced 5 W&B file(s), 13 media file(s), 845 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230905_011709-gj6k78no/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1316584ebe144e61b89a9d0bb94422e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5b245fff5fd48eb87dcde9fd7357247",
              "IPY_MODEL_0b564972fd49480f94fbec4eb999be62"
            ],
            "layout": "IPY_MODEL_3a37d7fc32774a749c2ee4d2c1272561"
          }
        },
        "b5b245fff5fd48eb87dcde9fd7357247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5d28a644a834a0c878ba03362f667c7",
            "placeholder": "​",
            "style": "IPY_MODEL_a0415b0c5b864c7c873771f54c2e42db",
            "value": "46.194 MB of 46.194 MB uploaded (42.402 MB deduped)\r"
          }
        },
        "0b564972fd49480f94fbec4eb999be62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c92e15f7a0624339836c624ba9b40b8a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51d981534b334f28a3661eaa7faa47d3",
            "value": 1
          }
        },
        "3a37d7fc32774a749c2ee4d2c1272561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5d28a644a834a0c878ba03362f667c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0415b0c5b864c7c873771f54c2e42db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c92e15f7a0624339836c624ba9b40b8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51d981534b334f28a3661eaa7faa47d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}